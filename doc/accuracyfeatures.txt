Feature #1: Accuracy metric

Provides an named transform for measuring accuracy of a given configuration.
This transform takes as input all the inputs and outputs of the original
transform and produces a double between 0.0 and 1.0 signifying the accuracy
achieved.  The autotuner uses this accuracy tester during training to classify
candidate algorithms.

For now the keyword is 'accuracy_metric', open to better names.  Perhaps just
'metric'?

Examples:

transform Foo
from A[n]
to B[n]
accuracy_metric Bar
{
...
}

transform Bar
from A[n], B[n]
to Accuracy 
{
...
}

----------------------

Feature #2: Iterative algorithms

A "for_enough" loop that lets the compiler decide how many iterations of
a loop should be run.  For this to make sense running the loop more times
should increase accuracy.

Example:

transform Foo
from A[n]
to B[n]
accuracy_metric Bar
{
  to(B b) from(A a) {
    for_enough(1,10) //1,10 is min,max (optional)
    {
      IterativeStep(b, a); 
    }
  }
}

-------------------------

Feature #3: Grid coarsening

This does not have its own language feature instead the user should use
intermediate matrices to represent data transformations.

The compiler support for this involves allowing tunables to be used in
matrix sizes.

Example:

transform Resampler
tunable c(1,10) //int from 1 to 10
from A[n]
through Aprime[n/c] 
to B[n/c] 
{
...
}








